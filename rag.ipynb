{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ecbfb60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afe7f286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from html_to_markdown import convert, convert_with_inline_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45166717",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3f02d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFLUENCE_SPACE_ID = '163973'\n",
    "ALL_PAGES_IN_SPACE_URL = f\"https://pokarnah.atlassian.net/wiki/api/v2/spaces/{CONFLUENCE_SPACE_ID}/pages\"\n",
    "\n",
    "auth = HTTPBasicAuth(\"pokarnah@gmail.com\", os.environ.get(\"CONFLUENCE_API_KEY\"))\n",
    "\n",
    "headers = {\n",
    "  \"Accept\": \"application/json\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "972bd78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['65706', '164078', '2555906', '2555913', '2555975', '2588685', '2654212', '2654222', '2719752', '2719770', '2719786', '2818118', '2883592', '2916355', '2981895', '3080227', '3112961', '3211265', '3211289', '3244043', '3276801', '3375105', '3375122']\n"
     ]
    }
   ],
   "source": [
    "response = requests.request(\n",
    "    \"GET\",\n",
    "    ALL_PAGES_IN_SPACE_URL,\n",
    "    headers=headers,\n",
    "    auth=auth\n",
    ")\n",
    "\n",
    "confluence_page_ids = []\n",
    "if response.status_code == 200:\n",
    "    data = json.loads(response.text)\n",
    "    results = data['results']\n",
    "    for result in results:\n",
    "        confluence_page_ids.append(result['id'])\n",
    "\n",
    "print(confluence_page_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "831f8bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25659\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"body-format\": \"storage\"\n",
    "}\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for page in confluence_page_ids:\n",
    "    PAGE_URL = f\"https://pokarnah.atlassian.net/wiki/api/v2/pages/{page}\"\n",
    "    \n",
    "    response = requests.request(\n",
    "        \"GET\",\n",
    "        PAGE_URL,\n",
    "        headers=headers,\n",
    "        params=params,\n",
    "        auth=auth\n",
    "    )\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = json.loads(response.text)\n",
    "        html = data['body']['storage']['value']\n",
    "        text = convert(html=html)\n",
    "        text = text.split(' ')\n",
    "        dataset.extend(text)\n",
    "\n",
    "\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a430f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4874959",
   "metadata": {},
   "source": [
    "# Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b972bc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0acf6f",
   "metadata": {},
   "source": [
    "### Fixed Size Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f543648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding(text):\n",
    "    response = client.embeddings.create(\n",
    "        model=\"text-embedding-3-small\",\n",
    "        input=text\n",
    "    )\n",
    "    return response.data[0].embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24e2d338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n",
      "1536\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 512\n",
    "VECTOR_DB = []\n",
    "\n",
    "for i in range(0, len(dataset), chunk_size):\n",
    "    chunk = dataset[i:i+chunk_size]\n",
    "    chunk = ' '.join(chunk)\n",
    "    embedding = create_embedding(text=chunk)\n",
    "    print(len(embedding))\n",
    "    VECTOR_DB.append((chunk, embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00db312",
   "metadata": {},
   "source": [
    "# Retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64d9269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    if len(a) != len(b):\n",
    "        raise Exception(\"Vectors of unequal length\")\n",
    "\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "\n",
    "    if norm_a == 0 or norm_b == 0:\n",
    "        raise Exception(\"Zero in denominator\")\n",
    "    similarity = dot_product / (norm_a * norm_b)\n",
    "    return similarity\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9629bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9922778767136677"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([1, 2], [2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77fade6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retreive(query_embedding, top_n=3):\n",
    "    similarities = []\n",
    "    for chunk, embedding in VECTOR_DB:\n",
    "        query_embedding = np.array(query_embedding)\n",
    "        embedding = np.array(embedding)\n",
    "        similarity = cosine_similarity(query_embedding, embedding)\n",
    "        similarities.append((chunk, similarity))\n",
    "\n",
    "    similarities.sort(key=lambda x:x[1], reverse=True)\n",
    "    return similarities[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f93d33a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = input()\n",
    "query_embedding = create_embedding(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb6a5ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "retreived_knowledge = retreive(query_embedding=query_embedding)\n",
    "prompt_knowledge = '\\n'.join(chunk for chunk, similarity in retreived_knowledge) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4909944e",
   "metadata": {},
   "source": [
    "# Answer Generation Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f2550b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"DOCUMENT: {prompt_knowledge}\" + \"\\n\" + f\"QUESTION: {query}\" + \"\\n\\n\\n\" + \"Answer the users QUESTION using the DOCUMENT text above. Keep your answer ground in the facts of the DOCUMENT. If the DOCUMENT doesnâ€™t contain the facts to answer the QUESTION return {NONE}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bceb7c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e0619cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Chroma DB is an open-source vector database designed for efficiently storing, searching, and managing vector embeddings, which are numeric representations used in AI and machine learning for tasks like semantic search and recommendation systems. It enables fast similarity search and offers a simple API for developers, making it well-suited for building and deploying AI-driven applications. Chroma DB supports features such as vector storage and querying, ease of use with a Python-based API, flexible storage options, and integration with popular embedding models from platforms like Hugging Face and OpenAI.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023db1a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
